# -*- coding: utf-8 -*-
"""Titanic_EDA(TASK_1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K1shyqBOWXlX-oRb0WvhpfIonJPnxhJS

# **The Intern Academy**

---

### **TASK 1**: Titanic EDA (Exploratory Data Analysis)



---

### **SUBMITTED BY** : Akshat Jain
---

## **Dataset:**

---

https://www.kaggle.com/shuofxz/titanic-machine-learning-from-disaster/tasks?taskId=2692

**Importing required libraries**
"""

import numpy as np
import pandas as pd
import seaborn as sns

titanic = pd.read_csv("Train.csv") 
titanic.head(10)

"""## **Data Analysis**"""

titanic.shape

titanic.columns

titanic.info()

titanic.isna().sum()

"""
## **Data Visualization**"""

import matplotlib.pyplot as plt


plt.figure(figsize=(10,10))
sns.heatmap(titanic.corr(), annot=True, linewidths=0.5, fmt= '.3f')

titanic.corr()

def woman_or_ch_or_man(passenger):
    age, sex = passenger
    if age < 16:
        return "child"
    else:
        return dict(male="man", female="woman")[sex]

titanic["who"] = titanic[["Age", "Sex"]].apply(woman_or_ch_or_man, axis=1)
titanic.head()

titanic["adult_male"] = titanic.who == "man"
titanic.head()

titanic["deck"] = titanic.Cabin.str[0]
titanic.head()

titanic["alone"] = ~(titanic. Parch + titanic.SibSp  ).astype(bool)
titanic.head()

sns.factorplot("Pclass", "Survived", data=titanic).set(ylim=(0, 1))

sns.factorplot("Pclass", "Survived", data=titanic, hue="Sex")

sns.factorplot("Pclass", "Survived", data=titanic, hue="who")

sns.factorplot("alone", "Survived", data=titanic, hue="Sex")

sns.factorplot("adult_male", "Survived", data=titanic, hue="Sex")

sns.barplot("deck", "Survived", data=titanic,order=['A','B','C','D','E','F','G'])

sns.factorplot("alone", "Survived", data=titanic, hue="Sex",col="Pclass")

"""## **Data Preprocessing**"""

#encoding deck

dk = {"A": 1, "B": 2, "C": 3, "D": 4, "E": 5, "F": 6, "G": 7}
titanic['deck']=titanic.deck.map(dk)
titanic.head()

# encoding embarked


titanic['Embarked'].value_counts()

e = {'S':3,'Q':2, 'C':1}
titanic['Embarked']=titanic.Embarked.map(e)
titanic.head()

# encoding gender

genders = {"male": 0, "female": 1}
titanic['Sex'] = titanic['Sex'].map(genders)
titanic.head()

#encoding who

wh = {'child':3,'woman':2, 'man':1}
titanic['who']=titanic.who.map(wh)

titanic.head()

#imputing deck
titanic['deck']=titanic['deck'].fillna(0)
titanic.head()

#imputing embarked

titanic['Embarked'].value_counts()

titanic['Embarked']=titanic['Embarked'].fillna('3.0')
titanic.head()

#imputing age

m=titanic['Age'].mean()
m

titanic['Age']=titanic['Age'].fillna(m)
titanic.head()

"""## **Adding New Features**"""

def process_family(parameters):
     
    x,y=parameters
    
    
    family_size = x+ y + 1
    
    if (family_size==1):
      return 1 # for singleton
    elif(2<= family_size <= 4 ):
      return 2 #for small family
    else:
      return 3 #for big family

titanic['FAM_SIZE']= titanic[['Parch','SibSp']].apply(process_family, axis=1)
titanic.head()

# to get title from the name.

titles = set()
for name in titanic['Name']:
    titles.add(name.split(',')[1].split('.')[0].strip())

titles

len(titles)

title_Dictionary = {
    "Capt": "Officer",
    "Col": "Officer",
    "Major": "Officer",
    "Jonkheer": "Royalty",
    "Don": "Royalty",
    "Sir" : "Royalty",
    "Dr": "Officer",
    "Rev": "Officer",
    "the Countess":"Royalty",
    "Mme": "Mrs",
    "Mlle": "Miss",
    "Ms": "Mrs",
    "Mr" : "Mr",
    "Mrs" : "Mrs",
    "Miss" : "Miss",
    "Master" : "Master",
    "Lady" : "Royalty"
}

def get_titles():
    
    titanic['title'] = titanic['Name'].map(lambda Name:Name.split(',')[1].split('.')[0].strip())
    
    
    
    titanic['title'] = titanic.title.map(title_Dictionary)
    return titanic

titanic = get_titles()
titanic.head()

titles_dummies = pd.get_dummies(titanic['title'], prefix='title')
titanic = pd.concat([titanic, titles_dummies], axis=1)
titanic.head()

def new_fe(parameters):
  p,w=parameters
  
  if (p==1):
    if (w==1):
      return 1
    elif (w==2):
      return 2
    elif (w==3):
      return 3
  elif (p==2):
    if (w==1):
      return 4
    elif (w==2):
      return 5
    elif (w==3):
      return 6
  elif (p==3):
    if (w==1):
      return 7
    elif (w==2):
      return 8
    elif (w==3):
      return 9

titanic['pcl_wh']= titanic[['Pclass','who']].apply(new_fe, axis=1)
titanic.head()

titanic.columns

drop_list=['Name','Ticket','Fare', 'Cabin','title']
titanic = titanic.drop(drop_list, axis=1)
titanic.head()

plt.figure(figsize=(20,20))
sns.heatmap(titanic.corr(), annot=True, linewidths=0.5, fmt= '.3f')

"""## **Build the Models**"""

X_train = titanic.drop("Survived", axis=1)
Y_train = titanic["Survived"]

from sklearn.model_selection import train_test_split

# splitting data in training set(80%) and test set(20%).
x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2)

"""
## Logistic Regression"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression() #create the object of the model
lr = lr.fit(x_train,y_train)

from sklearn.metrics import accuracy_score, confusion_matrix

act = accuracy_score(y_train,lr.predict(x_train))
print('Training Accuracy is: ',(act*100))

act = accuracy_score(y_test,lr.predict(x_test))
print('Test Accuracy is: ',(act*100))

"""## **Decision Tree Classifier**"""

from sklearn.tree import DecisionTreeClassifier


dt = DecisionTreeClassifier()
dt=dt.fit(x_train, y_train)

act = accuracy_score(y_train,dt.predict(x_train))
print('Training Accuracy is: ',(act*100))

act = accuracy_score(y_test,dt.predict(x_test))
print('Test Accuracy is: ',(act*100))

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier



rf = RandomForestClassifier(criterion = "gini", 
                                       min_samples_leaf = 3, 
                                       min_samples_split = 10,   
                                       n_estimators=100, 
                                       max_features=0.5, 
                                       oob_score=True, 
                                       random_state=1, 
                                       n_jobs=-1)
rf = rf.fit(x_train,y_train)

act = accuracy_score(y_train,rf.predict(x_train))
print('Training Accuracy is: ',(act*100))

act = accuracy_score(y_test,rf.predict(x_test))
print('Test Accuracy is: ',(act*100))

"""
### **Since Random Forest Classifier performs the best and it's test accuracy is 86.59217877094973 so that will be chosen as the final model.**"""